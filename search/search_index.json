{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Onepanel \u00b6 Onepanel is a portable and extensible platform that provides infrastructure and workflow automation for deep learning. It enables developers, ML practitioners and teams to build, train and deploy deep learning applications on a fully managed, distributed and elastic infrastructure. With Onepanel, code, data, parameters and environments are version controlled and reproducible, simplifying collaboration, knowledge transfer and accelerating ideation. In addition to the cloud offering, Onepanel is Kubernetes native and can be deployed anywhere. Register here to get started with Onepanel","title":"About Onepanel"},{"location":"#welcome-to-onepanel","text":"Onepanel is a portable and extensible platform that provides infrastructure and workflow automation for deep learning. It enables developers, ML practitioners and teams to build, train and deploy deep learning applications on a fully managed, distributed and elastic infrastructure. With Onepanel, code, data, parameters and environments are version controlled and reproducible, simplifying collaboration, knowledge transfer and accelerating ideation. In addition to the cloud offering, Onepanel is Kubernetes native and can be deployed anywhere. Register here to get started with Onepanel","title":"Welcome to Onepanel"},{"location":"cli/","text":"You can use Onepanel CLI to run commands from any terminal or integrate Onepanel into your CI/CD process. Alternatively, you can use Onepanel SDK to interact with Onepanel programmatically. Info See Get started with Onepanel CLI for installation instructions Commands \u00b6 Command Description onepanel login Login to Onepanel onepanel logout Log out of Onepanel onepanel projects Project commands onepanel datasets Dataset commands onepanel jobs Job commands onepanel download Download a dataset or job output onepanel environments list List available environments onepanel machine-types list List available machine types onepanel volume-types list List available volume types","title":"Overview"},{"location":"cli/#commands","text":"Command Description onepanel login Login to Onepanel onepanel logout Log out of Onepanel onepanel projects Project commands onepanel datasets Dataset commands onepanel jobs Job commands onepanel download Download a dataset or job output onepanel environments list List available environments onepanel machine-types list List available machine types onepanel volume-types list List available volume types","title":"Commands"},{"location":"cli/datasets-create/","text":"Create Dataset in a local named directory and in Onepanel. Syntax \u00b6 onepanel datasets create [ OPTIONS ] NAME Options \u00b6 --help Show this message and exit. Examples \u00b6 Create Dataset in named directory and in Onepanel: onepanel datasets create my - dataset","title":"onepanel datasets create"},{"location":"cli/datasets-create/#syntax","text":"onepanel datasets create [ OPTIONS ] NAME","title":"Syntax"},{"location":"cli/datasets-create/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"cli/datasets-create/#examples","text":"Create Dataset in named directory and in Onepanel: onepanel datasets create my - dataset","title":"Examples"},{"location":"cli/datasets-init/","text":"Initialize Dataset in current working directory working (cwd) and in Onepanel. Syntax \u00b6 onepanel datasets init [ OPTIONS ] Options \u00b6 -n , --name Dataset name. --help Show this message and exit. Examples \u00b6 Initialize Dataset in cwd, will be prompted for name, will default to cwd name: onepanel datasets init Initialize Dataset in current directory and add a name: onepanel datasets init - n different - name - from - cwd","title":"onepanel datasets init"},{"location":"cli/datasets-init/#syntax","text":"onepanel datasets init [ OPTIONS ]","title":"Syntax"},{"location":"cli/datasets-init/#options","text":"-n , --name Dataset name. --help Show this message and exit.","title":"Options"},{"location":"cli/datasets-init/#examples","text":"Initialize Dataset in cwd, will be prompted for name, will default to cwd name: onepanel datasets init Initialize Dataset in current directory and add a name: onepanel datasets init - n different - name - from - cwd","title":"Examples"},{"location":"cli/download/","text":"Download Dataset or Job output. Syntax \u00b6 onepanel download [ OPTIONS ] Dataset download syntax will look like this: onepanel download < account >/ datasets /< dataset > Job output download syntax will look like this: onepanel download < account >/ projects /< project >/ jobs /< job - number > Options \u00b6 --delete Deletes files locally that are not in the Dataset. --archive Download Job output as a compressed file. Applies to Job output only. -q , --quiet Minimize chatter from executed commands. -b , --background Run the download in the background. Will work even if SSH session is terminated. -v , --version The version of the Dataset. If none is provided, latest is used. --include Only download files matching this regex pattern. --help Show this message and exit. Examples \u00b6 Datasets \u00b6 Download latest Dataset version: onepanel download onepanel - demo / datasets / mnist Download a specific Dataset version: onepanel download onepanel - demo / datasets / mnist - v 2 Download Dataset into a specific directory (defaults to cwd if omitted): onepanel download onepanel - demo / datasets / mnist mnist - dataset Jobs \u00b6 Download Job output: onepanel download onepanel - demo / projects / examples / jobs / 100 Download Job output as a compressed file: onepanel download onepanel - demo / projects / examples / jobs / 100 --archive Download Job output into a specific directory (defaults to cwd if omitted): onepanel download onepanel - demo / projects / examples / jobs / 100 job - 100 - output","title":"onepanel download"},{"location":"cli/download/#syntax","text":"onepanel download [ OPTIONS ] Dataset download syntax will look like this: onepanel download < account >/ datasets /< dataset > Job output download syntax will look like this: onepanel download < account >/ projects /< project >/ jobs /< job - number >","title":"Syntax"},{"location":"cli/download/#options","text":"--delete Deletes files locally that are not in the Dataset. --archive Download Job output as a compressed file. Applies to Job output only. -q , --quiet Minimize chatter from executed commands. -b , --background Run the download in the background. Will work even if SSH session is terminated. -v , --version The version of the Dataset. If none is provided, latest is used. --include Only download files matching this regex pattern. --help Show this message and exit.","title":"Options"},{"location":"cli/download/#examples","text":"","title":"Examples"},{"location":"cli/download/#datasets","text":"Download latest Dataset version: onepanel download onepanel - demo / datasets / mnist Download a specific Dataset version: onepanel download onepanel - demo / datasets / mnist - v 2 Download Dataset into a specific directory (defaults to cwd if omitted): onepanel download onepanel - demo / datasets / mnist mnist - dataset","title":"Datasets"},{"location":"cli/download/#jobs","text":"Download Job output: onepanel download onepanel - demo / projects / examples / jobs / 100 Download Job output as a compressed file: onepanel download onepanel - demo / projects / examples / jobs / 100 --archive Download Job output into a specific directory (defaults to cwd if omitted): onepanel download onepanel - demo / projects / examples / jobs / 100 job - 100 - output","title":"Jobs"},{"location":"cli/environments-list/","text":"Show a list of available environments. Syntax \u00b6 onepanel environments list [ OPTIONS ] Options \u00b6 --help Show this message and exit.","title":"onepanel environments list"},{"location":"cli/environments-list/#syntax","text":"onepanel environments list [ OPTIONS ]","title":"Syntax"},{"location":"cli/environments-list/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"cli/jobs/","text":"","title":"onepanel jobs"},{"location":"cli/login/","text":"Login with a combination of either: Email and password Username and password Username and token Syntax \u00b6 onepanel login [ OPTIONS ] Options \u00b6 -e , --email Email you use to login to the website with. -u , --username The name you see in the top right of the website, once you log in. -p , --password Password you use when logging into the website. -t , --token One of the tokens that was created, from the settings > tokens and variables page. --help Show this message and exit. Examples \u00b6 Log in with email/password prompt: onepanel login Log in with email and token: onepanel login - u < username > - t < token >","title":"onepanel login"},{"location":"cli/login/#syntax","text":"onepanel login [ OPTIONS ]","title":"Syntax"},{"location":"cli/login/#options","text":"-e , --email Email you use to login to the website with. -u , --username The name you see in the top right of the website, once you log in. -p , --password Password you use when logging into the website. -t , --token One of the tokens that was created, from the settings > tokens and variables page. --help Show this message and exit.","title":"Options"},{"location":"cli/login/#examples","text":"Log in with email/password prompt: onepanel login Log in with email and token: onepanel login - u < username > - t < token >","title":"Examples"},{"location":"cli/logout/","text":"Log out current logged in user. Syntax \u00b6 onepanel logout [ OPTIONS ] Options \u00b6 --help Show this message and exit. Examples \u00b6 Log out current user: onepanel logout","title":"onepanel logout"},{"location":"cli/logout/#syntax","text":"onepanel logout [ OPTIONS ]","title":"Syntax"},{"location":"cli/logout/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"cli/logout/#examples","text":"Log out current user: onepanel logout","title":"Examples"},{"location":"cli/machine-types-list/","text":"Show a list of available machine types. Syntax \u00b6 onepanel machine - types list [ OPTIONS ] Options \u00b6 --help Show this message and exit.","title":"onepanel machine-types list"},{"location":"cli/machine-types-list/#syntax","text":"onepanel machine - types list [ OPTIONS ]","title":"Syntax"},{"location":"cli/machine-types-list/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"cli/projects-create/","text":"Create Project in a local named directory and in Onepanel. Syntax \u00b6 onepanel projects create [ OPTIONS ] NAME Options \u00b6 --help Show this message and exit. Examples \u00b6 Create Project in named directory and in Onepanel: onepanel projects create my - project Note Project name should be 3 to 25 characters long, lower case alphanumeric or '-' and must start and end with an alphanumeric character.","title":"onepanel projects create"},{"location":"cli/projects-create/#syntax","text":"onepanel projects create [ OPTIONS ] NAME","title":"Syntax"},{"location":"cli/projects-create/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"cli/projects-create/#examples","text":"Create Project in named directory and in Onepanel: onepanel projects create my - project Note Project name should be 3 to 25 characters long, lower case alphanumeric or '-' and must start and end with an alphanumeric character.","title":"Examples"},{"location":"cli/projects-init/","text":"Initialize Project in current working directory working (cwd) and in Onepanel. Syntax \u00b6 onepanel projects init [ OPTIONS ] Options \u00b6 --help Show this message and exit. Examples \u00b6 Initialize Project in cwd, will default to cwd name: onepanel projects init Note Project name should be 3 to 25 characters long, lower case alphanumeric or '-' and must start and end with an alphanumeric character. If the directory name doesn't match these criteria, you will be prompted to enter a valid name.","title":"onepanel projects init"},{"location":"cli/projects-init/#syntax","text":"onepanel projects init [ OPTIONS ]","title":"Syntax"},{"location":"cli/projects-init/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"cli/projects-init/#examples","text":"Initialize Project in cwd, will default to cwd name: onepanel projects init Note Project name should be 3 to 25 characters long, lower case alphanumeric or '-' and must start and end with an alphanumeric character. If the directory name doesn't match these criteria, you will be prompted to enter a valid name.","title":"Examples"},{"location":"cli/volume-types-list/","text":"Show a list of available volume types. Syntax \u00b6 onepanel volume - types list [ OPTIONS ] Options \u00b6 --help Show this message and exit.","title":"onepanel volume-types list"},{"location":"cli/volume-types-list/#syntax","text":"onepanel volume - types list [ OPTIONS ]","title":"Syntax"},{"location":"cli/volume-types-list/#options","text":"--help Show this message and exit.","title":"Options"},{"location":"environments/","text":"","title":"List of environments"},{"location":"environments/custom-packages/","text":"Onepanel comes pre-installed with many libraries for machine learning and deep learning. But in case you need additional packages, you can also install custom packages using pip , conda or apt-get . Installing PyPI packages \u00b6 You can install PyPi packages in two ways: Install using: pip install < package - name > Install persistent packages using a requirements.txt file that you commit into your repository. Refer to pip documention or requirements.txt documentation for more information. Installing Conda packages \u00b6 You can install Conda packages as follows: conda install < package_name > Note Your PyPi packages are installed in the same Conda environment. Refer to conda install documentation for more information and additional commands. Installing APT Packages \u00b6 You can also install app packages using apt-get as follows: sudo apt - get install < package - name > Refer to apt-get documentation for more information and additional commands.","title":"Custom packages"},{"location":"environments/custom-packages/#installing-pypi-packages","text":"You can install PyPi packages in two ways: Install using: pip install < package - name > Install persistent packages using a requirements.txt file that you commit into your repository. Refer to pip documention or requirements.txt documentation for more information.","title":"Installing PyPI packages"},{"location":"environments/custom-packages/#installing-conda-packages","text":"You can install Conda packages as follows: conda install < package_name > Note Your PyPi packages are installed in the same Conda environment. Refer to conda install documentation for more information and additional commands.","title":"Installing Conda packages"},{"location":"environments/custom-packages/#installing-apt-packages","text":"You can also install app packages using apt-get as follows: sudo apt - get install < package - name > Refer to apt-get documentation for more information and additional commands.","title":"Installing APT Packages"},{"location":"integrations/access-tokens/","text":"Create access token \u00b6 You can create an access token by following the steps shown below:","title":"Access tokens"},{"location":"integrations/access-tokens/#create-access-token","text":"You can create an access token by following the steps shown below:","title":"Create access token"},{"location":"machine-types/","text":"Info See per second pricing for more information Name Specifications cpu-2-8 CPU: 2, RAM: 8GB cpu-8-32 CPU: 8, RAM: 32GB gpu-4-26-1k80 GPU: 1 (Tesla K80), CPU: 4, RAM: 26GB gpu-8-52-1k80 GPU: 1 (Tesla K80), CPU: 8, RAM: 52GB gpu-4-26-1t4 GPU: 1 (Tesla T4), CPU: 4, RAM: 26GB gpu-8-52-1t4 GPU: 1 (Tesla T4), CPU: 8, RAM: 52GB gpu-8-52-1v100 GPU: 1 (Tesla V100), CPU: 8, RAM: 52GB gpu-16-104-2v100 GPU: 2 (Tesla V100), CPU: 16, RAM: 104GB gpu-32-208-4v100 GPU: 4 (Tesla V100), CPU: 32 RAM: 208GB gpu-64-416-8v100 GPU: 8 (Tesla V100), CPU: 64 RAM: 416GB cpu-2-8-spot CPU: 2, RAM: 8GB (spot) cpu-8-32-spot CPU: 8, RAM: 32GB (spot) gpu-4-26-1k80-spot GPU: 1 (Tesla K80), CPU: 4, RAM: 26GB (spot) gpu-8-52-1k80-spot GPU: 1 (Tesla K80), CPU: 8, RAM: 52GB (spot) gpu-4-26-1t4-spot GPU: 1 (Tesla T4), CPU: 4, RAM: 26GB (spot) gpu-8-52-1t4-spot GPU: 1 (Tesla T4), CPU: 8, RAM: 52GB (spot) gpu-8-52-1v100-spot GPU: 1 (Tesla V100), CPU: 8, RAM: 52GB (spot) gpu-16-104-2v100-spot GPU: 2 (Tesla V100), CPU: 16, RAM: 104GB (spot) gpu-32-208-4v100-spot GPU: 4 (Tesla V100), CPU: 32 RAM: 208GB (spot) gpu-64-416-8v100-spot GPU: 8 (Tesla V100), CPU: 64 RAM: 416GB (spot)","title":"List of machine types"},{"location":"machine-types/spot/","text":"Spot machines are highly affordable, short lived machines. They can be terminated at any time and run for a maximum of 24 hours. If your Workspace or Job is running and a Spot machine is in use, we will automatically pause your workspace and notify you. Select Spot on creation \u00b6 When creating a Workspace or Job, check the box next to Use spot machine . Switch to Spot in running Workspace \u00b6 To switch a Workspace to a Spot machine type: Click the Workspace name in the active tab. Click the icon next to Machine . Check the Use spot machine checkbox. Click Restart .","title":"Spot machines"},{"location":"machine-types/spot/#select-spot-on-creation","text":"When creating a Workspace or Job, check the box next to Use spot machine .","title":"Select Spot on creation"},{"location":"machine-types/spot/#switch-to-spot-in-running-workspace","text":"To switch a Workspace to a Spot machine type: Click the Workspace name in the active tab. Click the icon next to Machine . Check the Use spot machine checkbox. Click Restart .","title":"Switch to Spot in running Workspace"},{"location":"projects/","text":"A Project is a collection of your code repostitories, workspaces and jobs that you can share and collaborate on with your teammates. Your projects can also be forked by team members or made public so that others in the Onepanel community can view and fork them.","title":"Overview"},{"location":"projects/create/","text":"You can create a project from the web interface or using the CLI. Note To create a project via the CLI see these instructions To create project using the web interface: Go to Projects and click Create Project . Next, you can choose to Use a starter project or Create your own project . If you pick to start with a starter project, you can select a project from the list and click Next to get started. The project visibility will be set to private. If creating your own project, enter the name, description and pick the visiblity for your project. Project naming criteria are as follows: 3 to 25 characters Lower case alphanumeric, - or _ Must start and end with alphanumeric Optionally, enter the repository URL and optionally the branch name. URL format: https://github.com/account/project.git . Optionally and if this is a private repository, select Associate with git credentials . Select an existing or click Add new credentials to add and associate new credentials. Optionally, you can import this external repository to the Project's Local Repository by selecting Import this repository to Onepanel . Click Create .","title":"Create a new project"},{"location":"projects/delete/","text":"Warning Deleted projects cannot be restored. Note If you have running Workspaces or Jobs, you have to stop them first before deleting a project. To delete a Project: Go to a Project and click Settings in the side menu or in the project overview card. Click Delete Project . You will be prompted to confirm.","title":"Delete a project"},{"location":"projects/forking/","text":"Important When you fork a project, any associated Workspaces or the top 5 Jobs are also forked with the project. You may incur storage charges for any Job that is forked. All forked projects have their visibility set to private . Note A forked Project's visibility is set to private by default. To fork a project: Go to the Project's Overview page. Click Fork Project .","title":"Fork a project"},{"location":"projects/members/","text":"Add members \u00b6 Go to a Project and click Settings in the side menu or in the Project overview card. Click Members Type in the username of the members you would like to add, select their names and click Add Members . Remove a member \u00b6 Go to a Project and click Settings in the side menu or in the Project overview card. Click Members Next the member's username, click Remove .","title":"Manage members"},{"location":"projects/members/#add-members","text":"Go to a Project and click Settings in the side menu or in the Project overview card. Click Members Type in the username of the members you would like to add, select their names and click Add Members .","title":"Add members"},{"location":"projects/members/#remove-a-member","text":"Go to a Project and click Settings in the side menu or in the Project overview card. Click Members Next the member's username, click Remove .","title":"Remove a member"},{"location":"projects/repositories/","text":"You can add and remove repositories to projects at any time. You can then add these repositories to Workspace or Jobs as you launch them. Local repository \u00b6 Tip You can identify Local Repositories by their domain https://git.onepanel.io Each project comes with its own Local Repository , which is a Git repository managed by Onepanel. This repository is special because once you add a project member, they can automatically pull from and push to this repository instead of having to manage their credentials separately. Once you remove a member from a project, they are also removed from this repository. Other than these special properties, you can treat this repository just like your other Git repositories. Adding a repository \u00b6 You can add Git repositories in two ways. Add a repository directly to a Project \u00b6 Go to a Project and click Settings in the side menu or in the Project overview card. Click Repositories . Click Add Repository . Enter the repository URL and optionally the branch name. URL format: https://github.com/account/project.git . If this is a private repository, select Associate with git credentials . Select an existing or click Add new credentials to add and associate new credentials. Click Save . Add a repository in a Workspace or Job \u00b6 When creating a Job or Workspace, select New Repository . Enter the repository URL and optionally the branch name. URL format: https://github.com/account/project.git . If this is a private repository, select Associate with git credentials . Select an existing or click Add new credentials to add and associate new credentials. Continue completing the form and click Create .","title":"Manage repositories"},{"location":"projects/repositories/#local-repository","text":"Tip You can identify Local Repositories by their domain https://git.onepanel.io Each project comes with its own Local Repository , which is a Git repository managed by Onepanel. This repository is special because once you add a project member, they can automatically pull from and push to this repository instead of having to manage their credentials separately. Once you remove a member from a project, they are also removed from this repository. Other than these special properties, you can treat this repository just like your other Git repositories.","title":"Local repository"},{"location":"projects/repositories/#adding-a-repository","text":"You can add Git repositories in two ways.","title":"Adding a repository"},{"location":"projects/repositories/#add-a-repository-directly-to-a-project","text":"Go to a Project and click Settings in the side menu or in the Project overview card. Click Repositories . Click Add Repository . Enter the repository URL and optionally the branch name. URL format: https://github.com/account/project.git . If this is a private repository, select Associate with git credentials . Select an existing or click Add new credentials to add and associate new credentials. Click Save .","title":"Add a repository directly to a Project"},{"location":"projects/repositories/#add-a-repository-in-a-workspace-or-job","text":"When creating a Job or Workspace, select New Repository . Enter the repository URL and optionally the branch name. URL format: https://github.com/account/project.git . If this is a private repository, select Associate with git credentials . Select an existing or click Add new credentials to add and associate new credentials. Continue completing the form and click Create .","title":"Add a repository in a Workspace or Job"},{"location":"sdk/","text":"You can use Onepanel SDK to interact with Onepanel programmatically or integrate Onepanel into your CI/CD process. Info See Get started with Onepanel SDK for installation instructions","title":"Overview"},{"location":"start/cli/","text":"Installation \u00b6 Onepanel CLI is available on pypi and works on Windows, MacOS and Linux. To install Onepanel's CLI via pip : pip install -U onepanel We recommend installing onepanel into a python virtual environment, or a conda environment if you'd prefer. Example installation for python virtual environment pip [ pip3 ] install virtualenv mkdir folder_to_hold_virtual_python cd folder_to_hold_virtual_python virtualenv venv_2_7_16 [ <folder_that_tells_you_what_venv> ] cd venv_2_7_16 source bin/activate pip install -U onepanel Note CLI is pre-installed if you are using Onepanel Workspaces or Jobs. Tip The CLI is compatible with Python 2.7.x and Python >= 3.6.x, if you have both versions installed, you will need to use pip3 for Python >= 3.6.x. Authentication \u00b6 You can connect your Onepanel account to CLI by using the login command where you'll be prompted for your email and password: onepanel login Alternatively, you can create an access token and then login as follows: onepanel login -t <access-token> Check version \u00b6 onepanel --version Help and documentation \u00b6 Info See CLI documentation for additional commands You can add --help to any command to view information about its syntax and options, some examples: onepanel jobs --help onepanel jobs create --help","title":"Onepanel CLI"},{"location":"start/cli/#installation","text":"Onepanel CLI is available on pypi and works on Windows, MacOS and Linux. To install Onepanel's CLI via pip : pip install -U onepanel We recommend installing onepanel into a python virtual environment, or a conda environment if you'd prefer. Example installation for python virtual environment pip [ pip3 ] install virtualenv mkdir folder_to_hold_virtual_python cd folder_to_hold_virtual_python virtualenv venv_2_7_16 [ <folder_that_tells_you_what_venv> ] cd venv_2_7_16 source bin/activate pip install -U onepanel Note CLI is pre-installed if you are using Onepanel Workspaces or Jobs. Tip The CLI is compatible with Python 2.7.x and Python >= 3.6.x, if you have both versions installed, you will need to use pip3 for Python >= 3.6.x.","title":"Installation"},{"location":"start/cli/#authentication","text":"You can connect your Onepanel account to CLI by using the login command where you'll be prompted for your email and password: onepanel login Alternatively, you can create an access token and then login as follows: onepanel login -t <access-token>","title":"Authentication"},{"location":"start/cli/#check-version","text":"onepanel --version","title":"Check version"},{"location":"start/cli/#help-and-documentation","text":"Info See CLI documentation for additional commands You can add --help to any command to view information about its syntax and options, some examples: onepanel jobs --help onepanel jobs create --help","title":"Help and documentation"},{"location":"start/computer-vision/","text":"Computer Vision Mobile App \u2014 End-to-end AI pipeline demo using Onepanel \u00b6 The following Steps describes how to use the API's comsumed by the Demo Application. The Code for the App is Hosted here . The whole project can be visualized in the block diagram below : Steps \u00b6 Resume dataset-upload-api and run video_upload.py to start the API . The basic idea of file uploads is actually quite simple. It basically works like this: A <form> tag is marked with enctype=multipart/form-data and an <input type=file> is placed in that form. The application accesses the file from the files dictionary on the request object. use the save() method of the file to save the file permanently somewhere on the filesystem. import os from flask import Flask , flash , request , redirect , url_for from werkzeug.utils import secure_filename UPLOAD_FOLDER = '/path/to/the/uploads' ALLOWED_EXTENSIONS = { 'txt' , 'pdf' , 'png' , 'jpg' , 'jpeg' , 'gif' } app = Flask ( __name__ ) app . config [ 'UPLOAD_FOLDER' ] = UPLOAD_FOLDER The werkzeug.secure_filename() is explained a little bit later. The UPLOAD_FOLDER is where we will store the uploaded files and the ALLOWED_EXTENSIONS is the set of allowed file extensions. Next the functions that check if an extension is valid and that uploads the file and redirects the user to the URL for the uploaded file: def allowed_file ( filename ): return '.' in filename and \\ filename . rsplit ( '.' , 1 )[ 1 ] . lower () in ALLOWED_EXTENSIONS @app.route ( '/' , methods = [ 'GET' , 'POST' ]) def upload_file (): if request . method == 'POST' : # check if the post request has the file part if 'file' not in request . files : flash ( 'No file part' ) return redirect ( request . url ) file = request . files [ 'file' ] # if user does not select file, browser also # submit an empty part without filename if file . filename == '' : flash ( 'No selected file' ) return redirect ( request . url ) if file and allowed_file ( file . filename ): filename = secure_filename ( file . filename ) file . save ( os . path . join ( app . config [ 'UPLOAD_FOLDER' ], filename )) return redirect ( url_for ( 'uploaded_file' , filename = filename )) return ''' <!doctype html> <title>Upload new File</title> <h1>Upload new File</h1> <form method=post enctype=multipart/form-data> <input type=file name=file> <input type=submit value=Upload> </form> ''' `` ` Annotation \u00b6 Once Data is Upload is in the workspace, create a Datset and Pull it into CVAT Workspace and start Annotating. Dump the annotations into a CVAT XML . Given a CVAT XML and a directory with the image dataset, this script reads the CVAT XML and writes the annotations in tfrecords format into a given directory in addition to the label map required for the tensorflow object detection API. Install necessary packages (including tensorflow). sudo apt-get update sudo apt-get install -y --no-install-recommends python3-pip python3-dev pip3 install -r requirements.txt 2. Install the tensorflow object detection API \u00b6 If it's already installed you can check your $PYTHONPATH and move on to the usage section. Here's a quick (unofficial) guide on how to do that. For more details follow the official guide INSTALL TENSORFLOW OBJECT DETECTION API . # clone the models repository git clone https://github.com/tensorflow/models.git # install some dependencies pip3 install --user Cython pip3 install --user contextlib2 pip3 install --user pillow pip3 install --user lxml pip3 install --user jupyter pip3 install --user matplotlib # clone and compile the cocoapi git clone https://github.com/cocodataset/cocoapi.git cd cocoapi/PythonAPI make cp -r pycocotools <path_to_models_repo>/models/research/ # Protobuf Compilation cd <path_to_models_repo>/models/research/ protoc object_detection/protos/*.proto --python_out = . # setup the PYTHONPATH export PYTHONPATH = $PYTHONPATH : ` pwd ` : ` pwd ` /slim ``` ## Usage Run the script. ``` bash $python3 converter.py --cvat-xml </path/to/cvat/xml> --image-dir </path/to/images> \\ --output-dir </path/to/output/directory> --attribute <attribute> Leave --attribute argument empty if you want the to consider CVAT labels as tfrecords labels, otherwise you can specify a used attribute name like --attribute <attribute> . Please run python converter.py --help for more details. Once Data is Annotated and Converted to tfrecords, use the Following to train a model using it $python /onepanel/code/models/research/object_detection/legacy/train.py \\ --train_dir = /onepanel/code/Custom-Mask-RCNN-using-Tensorfow-Object-detection-API/CP \\ --pipeline_config_path = /onepanel/code/Custom-Mask-RCNN-using-Tensorfow-Object-detection-API/mask_rcnn_inception_v2_coco.config Start the Inference API \u00b6 Once we\u2019ve retrained our model and exported it to disk, we can host the model as a service. We\u2019ll load the model from disk with a simple function that takes the graph definition directly from the file and uses that to generate a graph. TensorFlow does most of this for us, Resume dataset-upload-api and run video_upload.py to start the API . detection_graph = tf . Graph () with detection_graph . as_default (): od_graph_def = tf . GraphDef () with tf . gfile . GFile ( PATH_TO_CKPT , 'rb' ) as fid : serialized_graph = fid . read () od_graph_def . ParseFromString ( serialized_graph ) tf . import_graph_def ( od_graph_def , name = '' ) label_map = label_map_util . load_labelmap ( PATH_TO_LABELS ) categories = label_map_util . convert_label_map_to_categories ( label_map , max_num_classes = NUM_CLASSES , use_display_name = True ) category_index = label_map_util . create_category_index ( categories ) def load_image_into_numpy_array ( image ): ( im_width , im_height ) = image . size return np . array ( image . getdata ()) . reshape ( ( im_height , im_width , 3 )) . astype ( np . uint8 ) Using Flask, much of the heavy-lifting around configuring a server and handling requests is done for us. After we\u2019ve created a Flask app object: app = Flask ( __name__ ) Then, we can easily create routes for where our classification service will live. Let\u2019s create a default route to our classify() function that will allow us to pass an image to the endpoint for identification. @app.route ( '/' ) def uploaded_file ( filename ): PATH_TO_TEST_IMAGES_DIR = app . config [ 'UPLOAD_FOLDER' ] TEST_IMAGE_PATHS = [ os . path . join ( PATH_TO_TEST_IMAGES_DIR , filename . format ( i )) for i in range ( 1 , 2 ) ] IMAGE_SIZE = ( 12 , 8 ) with detection_graph . as_default (): with tf . Session ( graph = detection_graph ) as sess : for image_path in TEST_IMAGE_PATHS : image = Image . open ( image_path ) image_np = load_image_into_numpy_array ( image ) image_np_expanded = np . expand_dims ( image_np , axis = 0 ) image_tensor = detection_graph . get_tensor_by_name ( 'image_tensor:0' ) boxes = detection_graph . get_tensor_by_name ( 'detection_boxes:0' ) scores = detection_graph . get_tensor_by_name ( 'detection_scores:0' ) classes = detection_graph . get_tensor_by_name ( 'detection_classes:0' ) num_detections = detection_graph . get_tensor_by_name ( 'num_detections:0' ) ( boxes , scores , classes , num_detections ) = sess . run ( [ boxes , scores , classes , num_detections ], feed_dict = { image_tensor : image_np_expanded }) vis_util . visualize_boxes_and_labels_on_image_array ( image_np , np . squeeze ( boxes ), np . squeeze ( classes ) . astype ( np . int32 ), np . squeeze ( scores ), category_index , use_normalized_coordinates = True , line_thickness = 8 ) im = Image . fromarray ( image_np ) im . save ( 'uploads/' + filename ) return send_from_directory ( app . config [ 'UPLOAD_FOLDER' ], filename ) Using the decorator syntax to define the route, it will configure the service so that our uploaded_file() function will be called every time someone hits the root of our service address. We said we wanted users to be able to specify a file to be identified so we\u2019ll store that as a parameter from the request: file_name = request . args [ 'file' ] `` In an actual app , we \u2019 d probably populate this from a form attachment or URL. For our example , we \u2019 ll simply let users specify a path to the file that they want to be identified . We can then read the image file and turn it into a tensor to be used as input to the graph we loaded previously . The base script included a number of useful functions including read_tensor_from_image_file () which will take the image file and turn it into a tensor to use as input by using a small custom TensorFlow graph . Running the inference on our graph with this image is again quite straightforward : `` ` python ( boxes , scores , classes , num_detections ) = sess . run ( [ boxes , scores , classes , num_detections ], feed_dict = { image_tensor : image_np_expanded }) `` ` In this line , the variable t represents the image tensor that was created by read_tensor_from_image_file () function . TensorFlow will then take that image and run the new retrained model to generate predictions . Those predictions come as a series of probabilities that indicate which of the classes ( poodle , pug , or wiener dog ) is the most likely . Since this is just a prediction service , it will simply return a JSON representation of the arrays . Inside our script we can start our service with : `` ` python app . run ( debug = True , port = 5000 ) Then, if we want to launch the script from the command line, all we have to do is run python app.py and it will initialize and start running on port 5000. Using the Service \u00b6 We can now use this service either by visiting it in a web browser or generally making any REST call on that port. For an easy test we can access it using following code snippet: import os import requests url = 'http://0.0.0.0:5000/onepanel-demo/projects/mobile-demo/workspaces/classification/api/upload' path_img = '/onepanel/code/FlaskObjectDetection/centaur_2.mpg' with open ( path_img , 'rb' ) as img : name_img = os . path . basename ( path_img ) files = { 'file' : ( name_img , img , 'multipart/form-data' ,{ 'Expires' : '0' }) } with requests . Session () as s : r = s . post ( url , files = files ) print ( r . status_code ) Download APP \u00b6 Download the Android app by scanning the QR or click on this Link","title":"Demo - Computer Vision"},{"location":"start/computer-vision/#computer-vision-mobile-app-end-to-end-ai-pipeline-demo-using-onepanel","text":"The following Steps describes how to use the API's comsumed by the Demo Application. The Code for the App is Hosted here . The whole project can be visualized in the block diagram below :","title":"Computer Vision Mobile App \u2014 End-to-end AI pipeline demo using Onepanel"},{"location":"start/computer-vision/#steps","text":"Resume dataset-upload-api and run video_upload.py to start the API . The basic idea of file uploads is actually quite simple. It basically works like this: A <form> tag is marked with enctype=multipart/form-data and an <input type=file> is placed in that form. The application accesses the file from the files dictionary on the request object. use the save() method of the file to save the file permanently somewhere on the filesystem. import os from flask import Flask , flash , request , redirect , url_for from werkzeug.utils import secure_filename UPLOAD_FOLDER = '/path/to/the/uploads' ALLOWED_EXTENSIONS = { 'txt' , 'pdf' , 'png' , 'jpg' , 'jpeg' , 'gif' } app = Flask ( __name__ ) app . config [ 'UPLOAD_FOLDER' ] = UPLOAD_FOLDER The werkzeug.secure_filename() is explained a little bit later. The UPLOAD_FOLDER is where we will store the uploaded files and the ALLOWED_EXTENSIONS is the set of allowed file extensions. Next the functions that check if an extension is valid and that uploads the file and redirects the user to the URL for the uploaded file: def allowed_file ( filename ): return '.' in filename and \\ filename . rsplit ( '.' , 1 )[ 1 ] . lower () in ALLOWED_EXTENSIONS @app.route ( '/' , methods = [ 'GET' , 'POST' ]) def upload_file (): if request . method == 'POST' : # check if the post request has the file part if 'file' not in request . files : flash ( 'No file part' ) return redirect ( request . url ) file = request . files [ 'file' ] # if user does not select file, browser also # submit an empty part without filename if file . filename == '' : flash ( 'No selected file' ) return redirect ( request . url ) if file and allowed_file ( file . filename ): filename = secure_filename ( file . filename ) file . save ( os . path . join ( app . config [ 'UPLOAD_FOLDER' ], filename )) return redirect ( url_for ( 'uploaded_file' , filename = filename )) return ''' <!doctype html> <title>Upload new File</title> <h1>Upload new File</h1> <form method=post enctype=multipart/form-data> <input type=file name=file> <input type=submit value=Upload> </form> ''' `` `","title":"Steps"},{"location":"start/computer-vision/#annotation","text":"Once Data is Upload is in the workspace, create a Datset and Pull it into CVAT Workspace and start Annotating. Dump the annotations into a CVAT XML . Given a CVAT XML and a directory with the image dataset, this script reads the CVAT XML and writes the annotations in tfrecords format into a given directory in addition to the label map required for the tensorflow object detection API. Install necessary packages (including tensorflow). sudo apt-get update sudo apt-get install -y --no-install-recommends python3-pip python3-dev pip3 install -r requirements.txt","title":"Annotation"},{"location":"start/computer-vision/#2-install-the-tensorflow-object-detection-api","text":"If it's already installed you can check your $PYTHONPATH and move on to the usage section. Here's a quick (unofficial) guide on how to do that. For more details follow the official guide INSTALL TENSORFLOW OBJECT DETECTION API . # clone the models repository git clone https://github.com/tensorflow/models.git # install some dependencies pip3 install --user Cython pip3 install --user contextlib2 pip3 install --user pillow pip3 install --user lxml pip3 install --user jupyter pip3 install --user matplotlib # clone and compile the cocoapi git clone https://github.com/cocodataset/cocoapi.git cd cocoapi/PythonAPI make cp -r pycocotools <path_to_models_repo>/models/research/ # Protobuf Compilation cd <path_to_models_repo>/models/research/ protoc object_detection/protos/*.proto --python_out = . # setup the PYTHONPATH export PYTHONPATH = $PYTHONPATH : ` pwd ` : ` pwd ` /slim ``` ## Usage Run the script. ``` bash $python3 converter.py --cvat-xml </path/to/cvat/xml> --image-dir </path/to/images> \\ --output-dir </path/to/output/directory> --attribute <attribute> Leave --attribute argument empty if you want the to consider CVAT labels as tfrecords labels, otherwise you can specify a used attribute name like --attribute <attribute> . Please run python converter.py --help for more details. Once Data is Annotated and Converted to tfrecords, use the Following to train a model using it $python /onepanel/code/models/research/object_detection/legacy/train.py \\ --train_dir = /onepanel/code/Custom-Mask-RCNN-using-Tensorfow-Object-detection-API/CP \\ --pipeline_config_path = /onepanel/code/Custom-Mask-RCNN-using-Tensorfow-Object-detection-API/mask_rcnn_inception_v2_coco.config","title":"2. Install the tensorflow object detection API"},{"location":"start/computer-vision/#start-the-inference-api","text":"Once we\u2019ve retrained our model and exported it to disk, we can host the model as a service. We\u2019ll load the model from disk with a simple function that takes the graph definition directly from the file and uses that to generate a graph. TensorFlow does most of this for us, Resume dataset-upload-api and run video_upload.py to start the API . detection_graph = tf . Graph () with detection_graph . as_default (): od_graph_def = tf . GraphDef () with tf . gfile . GFile ( PATH_TO_CKPT , 'rb' ) as fid : serialized_graph = fid . read () od_graph_def . ParseFromString ( serialized_graph ) tf . import_graph_def ( od_graph_def , name = '' ) label_map = label_map_util . load_labelmap ( PATH_TO_LABELS ) categories = label_map_util . convert_label_map_to_categories ( label_map , max_num_classes = NUM_CLASSES , use_display_name = True ) category_index = label_map_util . create_category_index ( categories ) def load_image_into_numpy_array ( image ): ( im_width , im_height ) = image . size return np . array ( image . getdata ()) . reshape ( ( im_height , im_width , 3 )) . astype ( np . uint8 ) Using Flask, much of the heavy-lifting around configuring a server and handling requests is done for us. After we\u2019ve created a Flask app object: app = Flask ( __name__ ) Then, we can easily create routes for where our classification service will live. Let\u2019s create a default route to our classify() function that will allow us to pass an image to the endpoint for identification. @app.route ( '/' ) def uploaded_file ( filename ): PATH_TO_TEST_IMAGES_DIR = app . config [ 'UPLOAD_FOLDER' ] TEST_IMAGE_PATHS = [ os . path . join ( PATH_TO_TEST_IMAGES_DIR , filename . format ( i )) for i in range ( 1 , 2 ) ] IMAGE_SIZE = ( 12 , 8 ) with detection_graph . as_default (): with tf . Session ( graph = detection_graph ) as sess : for image_path in TEST_IMAGE_PATHS : image = Image . open ( image_path ) image_np = load_image_into_numpy_array ( image ) image_np_expanded = np . expand_dims ( image_np , axis = 0 ) image_tensor = detection_graph . get_tensor_by_name ( 'image_tensor:0' ) boxes = detection_graph . get_tensor_by_name ( 'detection_boxes:0' ) scores = detection_graph . get_tensor_by_name ( 'detection_scores:0' ) classes = detection_graph . get_tensor_by_name ( 'detection_classes:0' ) num_detections = detection_graph . get_tensor_by_name ( 'num_detections:0' ) ( boxes , scores , classes , num_detections ) = sess . run ( [ boxes , scores , classes , num_detections ], feed_dict = { image_tensor : image_np_expanded }) vis_util . visualize_boxes_and_labels_on_image_array ( image_np , np . squeeze ( boxes ), np . squeeze ( classes ) . astype ( np . int32 ), np . squeeze ( scores ), category_index , use_normalized_coordinates = True , line_thickness = 8 ) im = Image . fromarray ( image_np ) im . save ( 'uploads/' + filename ) return send_from_directory ( app . config [ 'UPLOAD_FOLDER' ], filename ) Using the decorator syntax to define the route, it will configure the service so that our uploaded_file() function will be called every time someone hits the root of our service address. We said we wanted users to be able to specify a file to be identified so we\u2019ll store that as a parameter from the request: file_name = request . args [ 'file' ] `` In an actual app , we \u2019 d probably populate this from a form attachment or URL. For our example , we \u2019 ll simply let users specify a path to the file that they want to be identified . We can then read the image file and turn it into a tensor to be used as input to the graph we loaded previously . The base script included a number of useful functions including read_tensor_from_image_file () which will take the image file and turn it into a tensor to use as input by using a small custom TensorFlow graph . Running the inference on our graph with this image is again quite straightforward : `` ` python ( boxes , scores , classes , num_detections ) = sess . run ( [ boxes , scores , classes , num_detections ], feed_dict = { image_tensor : image_np_expanded }) `` ` In this line , the variable t represents the image tensor that was created by read_tensor_from_image_file () function . TensorFlow will then take that image and run the new retrained model to generate predictions . Those predictions come as a series of probabilities that indicate which of the classes ( poodle , pug , or wiener dog ) is the most likely . Since this is just a prediction service , it will simply return a JSON representation of the arrays . Inside our script we can start our service with : `` ` python app . run ( debug = True , port = 5000 ) Then, if we want to launch the script from the command line, all we have to do is run python app.py and it will initialize and start running on port 5000.","title":"Start the Inference API"},{"location":"start/computer-vision/#using-the-service","text":"We can now use this service either by visiting it in a web browser or generally making any REST call on that port. For an easy test we can access it using following code snippet: import os import requests url = 'http://0.0.0.0:5000/onepanel-demo/projects/mobile-demo/workspaces/classification/api/upload' path_img = '/onepanel/code/FlaskObjectDetection/centaur_2.mpg' with open ( path_img , 'rb' ) as img : name_img = os . path . basename ( path_img ) files = { 'file' : ( name_img , img , 'multipart/form-data' ,{ 'Expires' : '0' }) } with requests . Session () as s : r = s . post ( url , files = files ) print ( r . status_code )","title":"Using the Service"},{"location":"start/computer-vision/#download-app","text":"Download the Android app by scanning the QR or click on this Link","title":"Download APP"},{"location":"start/core-concepts/","text":"Projects \u00b6 A Project is a collection of your code repostitories, workspaces and jobs that you can share and collaborate on with your teammates. Your projects can also be forked by team members or made public so that others in the Onepanel community can view and fork them. Workspaces \u00b6 Workspaces are full Linux computing environments that come pre-installed with all the tools you need to explore data and build and experiment with your models. They include Python, JupyterLab, TensorFlow, PyTorch and other well known deep learning libraries and tools, as well as full terminal access. You can optionally install custom packages and dependencies into your workspaces. A single workspace can be paused and resumed at any time or be upgraded to multiple GPUs and downgraded with ease. Jobs \u00b6 Jobs allow you to execute your code in parallel, on multiple dedicated machines which are fully managed by Onepanel. With jobs, you can try different hyper-parameters, code and datasets and then compare the results and metrics for each job and continue iterating on the best results. While a job is running, you can view running logs, system metrics and training metrics. You also have full TensorBoard and terminal access to each running job. Once a job completes, a snapshot of logs, code, commands, datasets, environments and output is automatically saved. This allows you to share your results with others and reproduce/re-run the same experiments at a later time. Datasets \u00b6 With Onepanel Datasets , you can search or create version controlled datasets which you can then mount into a job or workspace . It is ideal to separate your data from your code from your data so you can collaborate with others and try different code on the same underlying dataset. Environments \u00b6 Onepanel Environments are CPU/GPU optimized and are pre-configured with all tools you need to build deep learning models, annotate your images and much more. They can be further customized with additional packages and dependencies .","title":"Core concepts"},{"location":"start/core-concepts/#projects","text":"A Project is a collection of your code repostitories, workspaces and jobs that you can share and collaborate on with your teammates. Your projects can also be forked by team members or made public so that others in the Onepanel community can view and fork them.","title":"Projects"},{"location":"start/core-concepts/#workspaces","text":"Workspaces are full Linux computing environments that come pre-installed with all the tools you need to explore data and build and experiment with your models. They include Python, JupyterLab, TensorFlow, PyTorch and other well known deep learning libraries and tools, as well as full terminal access. You can optionally install custom packages and dependencies into your workspaces. A single workspace can be paused and resumed at any time or be upgraded to multiple GPUs and downgraded with ease.","title":"Workspaces"},{"location":"start/core-concepts/#jobs","text":"Jobs allow you to execute your code in parallel, on multiple dedicated machines which are fully managed by Onepanel. With jobs, you can try different hyper-parameters, code and datasets and then compare the results and metrics for each job and continue iterating on the best results. While a job is running, you can view running logs, system metrics and training metrics. You also have full TensorBoard and terminal access to each running job. Once a job completes, a snapshot of logs, code, commands, datasets, environments and output is automatically saved. This allows you to share your results with others and reproduce/re-run the same experiments at a later time.","title":"Jobs"},{"location":"start/core-concepts/#datasets","text":"With Onepanel Datasets , you can search or create version controlled datasets which you can then mount into a job or workspace . It is ideal to separate your data from your code from your data so you can collaborate with others and try different code on the same underlying dataset.","title":"Datasets"},{"location":"start/core-concepts/#environments","text":"Onepanel Environments are CPU/GPU optimized and are pre-configured with all tools you need to build deep learning models, annotate your images and much more. They can be further customized with additional packages and dependencies .","title":"Environments"},{"location":"start/sdk/","text":"Installation \u00b6 Onepanel SDK is available as soon as you install Onepanel CLI Note SDK is pre-installed if you are using Onepanel Workspaces or Jobs. Authentication \u00b6 The recommended way to authenticate in Onepanel's SDK is to use an access token, you can create an access token and authenticate in the SDK as follows: from onepanel.sdk import Client # with username/access_token client = Client ( username = '<username>' , access_token = '<access token>' ) # or with email/access_token client = Client ( email = '<email>' , access_token = '<access token>' ) Example: create a job \u00b6 Example See the SDK notebook for a complete example from onepanel.models import Job from onepanel.sdk import Client # login with email/access_token client = Client ( email = '<email>' , access_token = '<access token>' ) # create a job job = Job () job . name = '<job-name>' job . project . uid = '<your-project-uid>' job . command = '<command>' job . machine_type . uid = '<machine-type-uid>' job . environment . uid = '<environment-uid>' job . volume_type . uid = '<volume-type-uid>' # create a job by uploading code from current directory job_uid = client . jobs . create ( job )","title":"Onepanel SDK"},{"location":"start/sdk/#installation","text":"Onepanel SDK is available as soon as you install Onepanel CLI Note SDK is pre-installed if you are using Onepanel Workspaces or Jobs.","title":"Installation"},{"location":"start/sdk/#authentication","text":"The recommended way to authenticate in Onepanel's SDK is to use an access token, you can create an access token and authenticate in the SDK as follows: from onepanel.sdk import Client # with username/access_token client = Client ( username = '<username>' , access_token = '<access token>' ) # or with email/access_token client = Client ( email = '<email>' , access_token = '<access token>' )","title":"Authentication"},{"location":"start/sdk/#example-create-a-job","text":"Example See the SDK notebook for a complete example from onepanel.models import Job from onepanel.sdk import Client # login with email/access_token client = Client ( email = '<email>' , access_token = '<access token>' ) # create a job job = Job () job . name = '<job-name>' job . project . uid = '<your-project-uid>' job . command = '<command>' job . machine_type . uid = '<machine-type-uid>' job . environment . uid = '<environment-uid>' job . volume_type . uid = '<volume-type-uid>' # create a job by uploading code from current directory job_uid = client . jobs . create ( job )","title":"Example: create a job"},{"location":"volume-types/","text":"Name Specifications ssd-10gb 10 GB SSD ssd-20gb 20 GB SSD ssd-40gb 40 GB SSD ssd-60gb 60 GB SSD ssd-80gb 80 GB SSD ssd-100gb 100 GB SSD ssd-200gb 200 GB SSD ssd-400gb 400 GB SSD ssd-600gb 600 GB SSD ssd-1tb 1 TB SSD ssd-2tb 2 TB SSD ssd-5tb 5 TB SSD ssd-10tb 10 TB SSD","title":"List of volume types"},{"location":"workspaces/","text":"Workspaces are full Linux computing environments that come pre-installed with all the tools you need to explore data and build and experiment with your models. They include Python, JupyterLab, TensorFlow, PyTorch and other well known deep learning libraries and tools, as well as full terminal access. You can optionally install custom packages and dependencies into your workspaces. A single workspace can be paused and resumed at any time or be upgraded to multiple GPUs and downgraded with ease.","title":"Overview"},{"location":"workspaces/create/","text":"To create a workspace: Go to a Project and click Workspaces . Click Create Workspace in the top right corner. Select an Environment and click Next . Next, enter a workspace name. Workspace naming criteria are as follows: 3 to 25 characters Lower case alphanumeric, - or _ Must start and end with alphanumeric Click Select machine to see a selection of machine types. A machine's price is displayed after you select it. If you are launching this workspace in a public Project, you have the option to pick its visibility . Optionally, you can select Use spot machine to select a Spot Machine . Select an existing or add a Code Repository , otherwise select None . The repository will be pulled into /onepanel/code folder. See managing repositories for more information. Optionally, mount Datasets by clicking Add Dataset . Optionally, change storage size by clicking Change . If you have selected Datasets, Onepanel will automatically adjust storage size based on total size of added Datasets plus an additional 50GB. Click Create to create your Workspace. Depending on your machine type, this could take up to 5 minutes.","title":"Create a workspace"},{"location":"workspaces/delete/","text":"You can delete a running or paused Workspace at any time. Warning Delete Workspaces cannot be restored. If you want to resume a Workspace at a later time, pause it instead. To delete a Workspace: Go to Workspaces page in a Project. Click the context menu for that Workspace and click Delete .","title":"Delete a workspace"},{"location":"workspaces/interactions/","text":"Switch between services \u00b6 You can switch between differen services by clicking the dropdown in Workspace tab. For example to switch to TensorBoard: Click the Workspace tab. Select the TensorBoard option. You can open any service full screen by clicking the icon in top right corner of the tab. SSH access \u00b6 You can access SSH through your browser in all Workspaces. Click Terminal in bottom right corner of Workspace detail page. This will expand the SSH terminal panel which will give you SSH access right through your browser. You can open terminal full screen by clicking the icon in top right corner of the panel. System metrics \u00b6 You view system metrics including CPU, GPU and memory usage by click System in the bottom right corner of Workspace detail page.","title":"Workspace interactions"},{"location":"workspaces/interactions/#switch-between-services","text":"You can switch between differen services by clicking the dropdown in Workspace tab. For example to switch to TensorBoard: Click the Workspace tab. Select the TensorBoard option. You can open any service full screen by clicking the icon in top right corner of the tab.","title":"Switch between services"},{"location":"workspaces/interactions/#ssh-access","text":"You can access SSH through your browser in all Workspaces. Click Terminal in bottom right corner of Workspace detail page. This will expand the SSH terminal panel which will give you SSH access right through your browser. You can open terminal full screen by clicking the icon in top right corner of the panel.","title":"SSH access"},{"location":"workspaces/interactions/#system-metrics","text":"You view system metrics including CPU, GPU and memory usage by click System in the bottom right corner of Workspace detail page.","title":"System metrics"},{"location":"workspaces/machine-types/","text":"Note Switching machine types will restart your Workspace. To switch a Workspace machine type: Click the Workspace name in the active tab. Click the icon next to Machine . Choose a new machine from the drop-down and click Restart .","title":"Switch machine types"},{"location":"workspaces/pause-resume/","text":"You can pause Workspaces at any time to save on compute costs. All your work remains in the Workspace for you to access at a later time when you resume your Workspace. Important Pausing workspaces stops all CPU/GPU/Memory charges for that Workspace. You will continue to be charged for storage however. Pause a Workspace \u00b6 You can pause a Workspace by clicking the Workspace name in active tab and clicking Pause . Alternatively, you can pause a Workspace by going to Workspaces page in a Project and clicking the context menu for that Workspace and clicking Pause . Resume a Workspace \u00b6 You can resume a paused Workspace by clicking the Workspace name in active tab and clicking Resume . Alternatively, you can resume a paused Workspace by going to Workspaces page in a Project and clicking the context menu for that Workspace and clicking Resume .","title":"Pause and resume"},{"location":"workspaces/pause-resume/#pause-a-workspace","text":"You can pause a Workspace by clicking the Workspace name in active tab and clicking Pause . Alternatively, you can pause a Workspace by going to Workspaces page in a Project and clicking the context menu for that Workspace and clicking Pause .","title":"Pause a Workspace"},{"location":"workspaces/pause-resume/#resume-a-workspace","text":"You can resume a paused Workspace by clicking the Workspace name in active tab and clicking Resume . Alternatively, you can resume a paused Workspace by going to Workspaces page in a Project and clicking the context menu for that Workspace and clicking Resume .","title":"Resume a Workspace"}]}